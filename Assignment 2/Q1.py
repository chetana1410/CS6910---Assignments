# -*- coding: utf-8 -*-
"""Q1 (1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bcj6-3fl2i79bj_Udu5XN60BCiuG4sYH
"""

from google.colab import drive
drive.mount("/content/gdrive")

import keras
from keras.models import Sequential
from keras.layers import Dense, Conv2D, Flatten,BatchNormalization,Dropout,Activation ,MaxPooling2D
from keras.preprocessing.image import ImageDataGenerator
from keras.losses import CategoricalCrossentropy
import PIL
import wandb
from wandb.keras import WandbCallback

wandb.login()

def cnn(n,num_filters,ker_size,activ,pool,num_nodes,filter_org,bn=0,dp='no'):
    


    model = Sequential()
    model.add(Conv2D(num_filters, (ker_size, ker_size), input_shape=(255,255,3)))
    model.add(Activation(activ))
    model.add(MaxPooling2D(pool_size=(pool, pool)))
    for i in range(1,n):
        if filter_org == 'double':
            num_filters *=2
        elif filter_org == 'half':
            num_filters *=1//2
            
        model.add(Conv2D(num_filters, (ker_size, ker_size)))
        if bn:
            model.add(BatchNormalization())
            
        model.add(Activation(activ))
        model.add(MaxPooling2D(pool_size=(pool, pool)))
        
    model.add(Flatten())
    model.add(Dense(num_nodes))
    model.add(Activation(activ))
    if dp != 'no':
        model.add(Dropout(dp))
        
    model.add(Dense(10, activation='softmax'))

    return model

def train():
    default_hyperparams = dict(
      bn=0,
      num_filters=64,
      fliter_org='same',
      dropout=0,
      data_aug=0,
      learning_rate=0.01,
      epochs=5,
      activ="ReLU",
    )

    
    
    wandb.init(config = default_hyperparams)
    config = wandb.config

    train_data_dir= '/content/gdrive/MyDrive/inaturalist_12K/train'

    if config.data_aug:
        
        train_datagen = ImageDataGenerator(
        rescale=1./255,
        validation_split=0.1) # set validation split
        
          #  agument_params={ #shear_range=0.2,
        #zoom_range=0.2,
        #horizontal_flip=True,}
    else:
        
        train_datagen = ImageDataGenerator(
        rescale=1./255,
        validation_split=0.1) # set validation split
    
    

    train_it = train_datagen.flow_from_directory(
        train_data_dir,
        #target_size=(img_height, img_width),
        batch_size=32,
        class_mode='categorical',
        subset='training') # set as training data

    val_it = train_datagen.flow_from_directory(
        train_data_dir, # same directory as training data
        #target_size=(img_height, img_width),
        batch_size=32,
        class_mode='categorical',
        subset='validation') # set as validation data
    
    # Your model here ...
    model = cnn(5,config.num_filters,7,config.activ,2,1024,config.filter_org,config.bn,config.dropout)
    
    model.compile(optimizer="Adam", loss=CategoricalCrossentropy(), metrics='acc')
    
    model.fit_generator(
    train_it,
    steps_per_epoch = train_it.samples // 32,
    validation_data = val_it, 
    validation_steps = val_it.samples // 32,
    epochs = config.epochs,
    callbacks=[WandbCallback()])
    
    
    train_loss, train_accuracy = model.evaluate_generator(train_it, callbacks=[WandbCallback()])
    val_loss, val_accuracy = model.evaluate_generator(val_it, callbacks=[WandbCallback()])
    #print('Val accuracy: ', accuracy*100)
    wandb.log({'val_loss':val_loss,'val_accuracy':val_accuracy,'train_oss': train_loss,'train_accuracy':train_accuracy }) # wandb.log to track custom metrics

sweep_config = {
   #'program': train(),
    'method': 'random',         
    'metric': {
        'name': 'val_accuracy',     
        'goal': 'maximize'      
    },
    'parameters': {
        'learning_rate': {
            'values': [1e-3]
        },
        'activ': {
            'values': ['relu']
        },
        'bn': {
            'values': [1, 0]
        },
        'num_filters': {
            'values': [32, 64, 128, 256]
        },
        'filter_org': {
            'values': ['same', 'double']
        },
        'epochs': {
            'values': [5]
        },
        'dropout': {
            'values': [0, 0.2, 0.3]
        },
        'data_aug': {
            'values': [0]
        },

        }
    }


sweep_id = wandb.sweep(sweep_config,project='asgn2')

wandb.agent(sweep_id, function=train)



